(window.webpackJsonp=window.webpackJsonp||[]).push([[141],{474:function(a,s,t){"use strict";t.r(s);var r=t(1),e=Object(r.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"hive整合hadoop通过flume-hue收集日志"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive整合hadoop通过flume-hue收集日志","aria-hidden":"true"}},[a._v("#")]),a._v(" hive整合hadoop通过flume+hue收集日志")]),a._v(" "),t("p",[a._v("hive作为hadoop集群架构之上的一个架构，通过一种类SQL的解析引擎来将作业转换成map/reduce执行的任务。")]),a._v(" "),t("p",[a._v("本文主要是分享基本的安装与使用经验。hive的实质是将表对应到HDFS中的目录。")]),a._v(" "),t("h2",{attrs:{id:"添加环境变量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#添加环境变量","aria-hidden":"true"}},[a._v("#")]),a._v(" 添加环境变量")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("JAVA_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/usr/local/jdk1.7.0_09"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(".:"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/lib:"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/jre/lib\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$JAVA_HOME")]),a._v("/bin\n\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/home/hadoop/hadoop-2.6.4"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_CONF_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/etc/hadoop/\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(".:"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/lib\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/bin:"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HADOOP_HOME")]),a._v("/sbin\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_USER_CLASSPATH_FIRST")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("true\n\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HIVE_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/home/hadoop/apache-hive-2.1.0-bin"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$CLASSPATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HIVE_HOME")]),a._v("/lib\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")])]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("$PATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HIVE_HOME")]),a._v("/bin:"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$HIVE_HOME")]),a._v("/conf\n")])])]),t("h2",{attrs:{id:"设置公钥本机免登陆密码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置公钥本机免登陆密码","aria-hidden":"true"}},[a._v("#")]),a._v(" 设置公钥本机免登陆密码")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("ssh-keygen\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cp")]),a._v(" /root/.ssh/id_rsa.pub  /root/.ssh/authorized_keys\n")])])]),t("h2",{attrs:{id:"安装java环境"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装java环境","aria-hidden":"true"}},[a._v("#")]),a._v(" 安装java环境")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" zxvf jdk-7u9-linux-x64.tar.gz\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("mv")]),a._v(" jdk1.7.0_09/ /usr/local/\n\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("ln")]),a._v(" -s /usr/local/jdk1.7.0_09/bin/java /usr/bin/\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("ln")]),a._v(" -s /usr/local/jdk1.7.0_09/bin/javac /usr/bin/\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("ln")]),a._v(" -s /usr/local/jdk1.7.0_09/bin/jar /usr/bin/\n")])])]),t("h2",{attrs:{id:"安装hadoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装hadoop","aria-hidden":"true"}},[a._v("#")]),a._v(" 安装hadoop")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wget")]),a._v(" http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.6.4/hadoop-2.6.4.tar.gz\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" zxvf hadoop-2.6.4.tar.gz\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" hadoop-2.6.4\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" etc/hadoop/hadoop-env.sh\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("JAVA_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/usr/local/jdk1.7.0_09\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" etc/hadoop/core-site.xml\n\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hadoop.tmp.dir"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("/home/ebuy/hadoop/hadoop-2.6.4/tmp"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\t\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- 如没有配置hadoop.tmp.dir参数，此时系统默认的临时目录为：/tmp/hadoo-hadoop\n\t\t而这个目录在每次重启后都会被干掉，必须重新执行format才行，否则会出错。 --"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("description"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("A base "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" other temporary directories."),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/description"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("file")]),a._v(" system properties --"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("fs.default.name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hdfs://localhost:900"),t("span",{pre:!0,attrs:{class:"token operator"}},[t("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("0")]),a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),t("h2",{attrs:{id:"启动及验证hadoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#启动及验证hadoop","aria-hidden":"true"}},[a._v("#")]),a._v(" 启动及验证hadoop")]),a._v(" "),t("h3",{attrs:{id:"格式化hdfs文件系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#格式化hdfs文件系统","aria-hidden":"true"}},[a._v("#")]),a._v(" 格式化HDFS文件系统")]),a._v(" "),t("p",[t("code",[a._v("hadoop namenode -format")])]),a._v(" "),t("h2",{attrs:{id:"启动hadoop"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#启动hadoop","aria-hidden":"true"}},[a._v("#")]),a._v(" 启动hadoop")]),a._v(" "),t("p",[t("code",[a._v("sh sbin/start-all.sh")])]),a._v(" "),t("p",[a._v("http://10.127.0.5:50070")]),a._v(" "),t("h2",{attrs:{id:"hdfs常用命令"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hdfs常用命令","aria-hidden":"true"}},[a._v("#")]),a._v(" hdfs常用命令")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("hdfs dfs -mkdir /tmp/hive\nhdfs dfs -ls  /tmp/hive/*\nhdfs dfs -cat /tmp/hive/123 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("  "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wc")]),a._v(" -l\nhdfs dfs -chmod "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("755")]),a._v(" /tmp/\nhdfs dfs -rmr /tmp/*\nhdfs dfs -rm -r -f -skipTrash  /ecoupon/cachemanage\nhdfs dfs -mkdir /user/hive/warehouse\nhdfs dfs -chmod "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("755")]),a._v(" /user/hive/warehouse\n")])])]),t("h2",{attrs:{id:"安装hive"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装hive","aria-hidden":"true"}},[a._v("#")]),a._v(" 安装hive")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("wget")]),a._v(" http://mirrors.hust.edu.cn/apache/hive/hive-1.2.1/apache-hive-1.2.1-bin.tar.gz\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("tar")]),a._v(" zxvf apache-hive-1.2.1-bin.tar.gz\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" apache-hive-1.2.1-bin\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("cd")]),a._v(" conf\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cp")]),a._v(" hive-default.xml.template   hive-site.xml\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cp")]),a._v(" hive-exec-log4j.properties.template  hive-exec-log4j.properties\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cp")]),a._v(" hive-log4j.properties.template  hive-log4j.properties\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cp")]),a._v(" hive-env.sh.template hive-env.sh\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" hive-env.sh\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HADOOP_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/home/ebuy/hadoop/hadoop-2.6.4\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("export")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("HIVE_CONF_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/home/ebuy/hadoop/apache-hive-1.2.1-bin/conf\n"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("cat")]),a._v(" hive-site.xml \n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("configuration"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- MySQ的URL配置 --"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("javax.jdo.option.ConnectionURL"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("jdbc:mysql://144.232.134.58:3306/hive?createDatabaseIfNotExist"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("true"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- 此处JDBC的驱动务必加上，对应的数据配置对应的驱动--"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("javax.jdo.option.ConnectionDriverName"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("com.mysql.jdbc.Driver"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n     "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("description"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("Driver class name "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" a JDBC metastore"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/description"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- 数据库的用户名配置--"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("javax.jdo.option.ConnectionUserName"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- 数据库密码配置--"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("javax.jdo.option.ConnectionPassword"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- HDFS路径hive表的存放位置--"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.metastore.warehouse.dir"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hdfs://localhost:9000//user/hive/warehouse"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("--HDFS路径，用于存储不同 map/reduce 阶段的执行计划和这些阶段的中间输出结果。 --"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.exec.scratchdir"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("/tmp"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("mapred.child.java.opts"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("-Xmx4096m"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("-- 日志的记录位置--"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.querylog.location"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("/home/ebuy/hadoop/apache-hive-1.2.1-bin/logs"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.metastore.local"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("false"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.server2.thrift.port"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1000")]),t("span",{pre:!0,attrs:{class:"token operator"}},[t("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("0")]),a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("hive.server2.thrift.bind.host"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("localhost"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/value"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/configuration"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n\n")])])]),t("p",[a._v("mysql连接驱动hive没有自带；需拷贝mysql-connector-java-5.1.21.jar到lib下,同时mysql据数据建表授权！")]),a._v(" "),t("p",[a._v("在HDFS上，新建hive的数据存储目录，以及MapReduce执行过程，生成的临时文件目录，执行命令如下，并赋值权限")]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[a._v("hdfs dfs -mkidr /tmp  \nhdfs dfs -mkidr /user/hive/warehouse  \nhdfs dfs -chmod g+w /tmp  \nhdfs dfs -chmod g+w /user/hive/warehouse  \n")])])]),t("h2",{attrs:{id:"启动hive-执行建表命令并导入数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#启动hive-执行建表命令并导入数据","aria-hidden":"true"}},[a._v("#")]),a._v(" 启动hive 执行建表命令并导入数据")]),a._v(" "),t("p",[a._v("执行命令")]),a._v(" "),t("p",[t("code",[a._v("./bin/hive")])]),a._v(" "),t("h2",{attrs:{id:"hiveserver2启动"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hiveserver2启动","aria-hidden":"true"}},[a._v("#")]),a._v(" Hiveserver2启动")]),a._v(" "),t("p",[a._v("HiveServer2作为一种服务接口，允许Hive远程客户端执行查询并返回结果；默认监听端口为10000。当前实现基于Thrift的RPC调用。是HiveServer的改进版本，支持多客户端的并发和权限控制.")]),a._v(" "),t("p",[t("code",[a._v("./bin/hiveserver2")])]),a._v(" "),t("h2",{attrs:{id:"fulme-hue"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fulme-hue","aria-hidden":"true"}},[a._v("#")]),a._v(" fulme+HUE")]),a._v(" "),t("p",[t("a",{attrs:{href:"http://linux48.com/2016-05-16-flume.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("fulme+HUE配置"),t("OutboundLink")],1)]),a._v(" "),t("div",{staticClass:"language-bash extra-class"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[a._v("vim")]),a._v(" hue/desktop/conf/pseudo-distributed.ini\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("hive_server_host")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("localhost\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("hive_server_port")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10000")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a._v("hive_conf_dir")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("/home/ebuy/hadoop/apache-hive-1.2.1-bin/conf\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);